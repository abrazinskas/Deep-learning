# Deep learning course materials

This repository contains labaratory(practical) and theoretical works that were conducted for the deep learning courses at the University of Amsterdam. 
The code for the practical assignments is written in python as available in the ipython format. 

## Course description
Deep learning is primarily a study of multi-layered neural networks, spanning over a great range of model architectures. More specifically, the following content will be the studied both from theoretical (during lectures) as well as from practical (during the practicals) point of view.
link :  http://coursecatalogue.uva.nl/xmlpages/page/2016-2017-en/search-course/course/30891
## Course contents

1. Linear regression, logistic regression, perceptrons. A recap of previous simple machine learning models

2. Back propagation and optimization. Since neural networks are notoriously difficult to train, we will deepen our understanding on how to optimize them both theoretically and practically.

3. Convolutional neural networks(CNN). The driving force behind the popularity of deep learning. CNNs have their main application in image recognition, object detection, automatic text translation and speech recognition.

4. Recurrent neural networks(RNN). CNNs or other traditional network architectures have only feedforward operations. With RNNs we add feedback to the model, thus providing it with memory. With RNNs one can build machines that write Shakespeare, automatic caption generators, automatic music generators or even machines that dream new pictures.

5. Transfer learning. Normally deep learning requires big data. For some problems big data is not available. With transfer learning one can combine different sources of data to build a more powerful model.

6. Restricted Boltzmann Machines, autoencoders. These are two examples of generative deep models that can train from unlabeled data. Other variants of deep learning models and architectures will also be presented.

## The MIT License (MIT)
Copyright (c) <2016> <ixlan>
